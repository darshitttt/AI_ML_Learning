{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised ML Process\n",
    "\n",
    "### ML Pathway\n",
    "\n",
    "1. Collect and Store Data\n",
    "2. Clean and Organise Data\n",
    "3. Exploratory Data Analysis (Stat Analysis, Visualisation)\n",
    "4. ML Models (for going beyond Data Analysis and creating product)\n",
    "    a. Supervised Learning: predict an outcome\n",
    "    b. Unsupervised Learning: discover patterns in Data\n",
    "\n",
    "\n",
    "### ML Process: Supervised ML Tasks\n",
    "\n",
    "- **Supervised ML**: Using *historical, labeled* data, predict a future outcome or result.\n",
    "- Start with collecting and organise a data set based on history\n",
    "- **Historical Labeled** dataset\n",
    "- If a new feature vector appears, the model should be able to predict the label\n",
    "\n",
    "\n",
    "### Supervised ML Process:\n",
    "- Data\n",
    "- X:Features, Y:Labels\n",
    "- Splitting training and testing dataset (complex: cross validation, etc)\n",
    "- Training/Fitting model\n",
    "- Evaluate performance: comparing predictions with actual labels from the test set\n",
    "- Fit/adjust model params\n",
    "- Deploy model as a product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "**HIstory and Motivation**:\n",
    "- grew out of need for improving navigation methods based on astronomy during the 1700s.\n",
    "- First public exposition on Linear Regression with least squares method in 1800..\n",
    "- Gauss claimed that he invented least-squares in 1790s..\n",
    "Building an intuitive understanding of Linear Regression: It implies a **constant straight line relationship**.\n",
    "The simplest relationship is y = x.\n",
    "Given the relationship of two or more variables, it becomes straightforward to predict the output value, when we encounter previously unseen feature values. \n",
    "\n",
    "**Important Point**: Real world data vairables hardly have a linear relationship, in this case we need to find a **line** that fits the data/that describes the relationship between the variables the best.\n",
    "- We need to reduce the distance of each point from the line we come up with. \n",
    "- **Ordinary Least Squares** works by minimising the sum of the squares of the differences between the observed dependent var in the given dataset and those predicted by the linear function.\n",
    "\n",
    "### OLS Equations\n",
    "\n",
    "The equation of a simple straight line is y = mx + b, where m is the slope of the line and b is the intercept with y-axis. With this simple equation, there is only room for one possible feature. \n",
    "- OLS will allow us directly solve for the slope m and intercept b given a set of datapoints for x and y.\n",
    "- In case of multiple features,we will need **Gradient Descent** and **Cost functions**.\n",
    "\n",
    "\n",
    "### Cost Functions:\n",
    "\n",
    "OLS is not suitable/suitable for multiple features. \n",
    "- The purpose is to define an appropriate error/cost function and to minimise it as much as possible so that our regression line fits the data in the best possible way. \n",
    "- **Residual error** is basically the difference between predicted value and the actual value, whereas, cost/loss functions are nothing but different variants of residual error.\n",
    "- **Recall from Calculus**: To minimise a function we can take its derivative and set it equal to zero. \n",
    "- But mathematically it is not practical and scalable to compute the minimal of a function like this, instead we use **Gradient Descent**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
